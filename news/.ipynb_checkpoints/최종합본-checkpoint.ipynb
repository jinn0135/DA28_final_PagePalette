{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf6d48d",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790bcb0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T03:59:13.348017Z",
     "start_time": "2023-07-04T03:59:09.571887Z"
    }
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "\n",
    "# crawling\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# time control\n",
    "from time import sleep\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import ckonlpy\n",
    "from ckonlpy.tag import Twitter\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "import openai\n",
    "\n",
    "# NLP Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "from wordcloud import WordCloud\n",
    "import cv2\n",
    "\n",
    "\n",
    "# customized functions\n",
    "from news_utils import *\n",
    "from news_crawling import *\n",
    "from news_utils import *\n",
    "from news_words import *\n",
    "from news_summarize import *\n",
    "\n",
    "# utils\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import warnings # FutureWarning 안보이게\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73201d49",
   "metadata": {},
   "source": [
    "# 다음 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabaa44c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:15.729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: Message: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1439 [00:01<27:32,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "prepared_urls = get_urls_daum()\n",
    "\n",
    "df_daum = pd.DataFrame({'URL':prepared_urls, '신문사':np.nan, '기자명':np.nan, '제목':np.nan, '본문':np.nan,\n",
    "                   '날짜':np.nan, '연':np.nan, '월':np.nan, '일':np.nan, '요일':np.nan})\n",
    "\n",
    "df_daum = news_crawler_daum(df_daum)\n",
    "display(df_daum.head(3))\n",
    "display(df_daum.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d258c37",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199e585",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:16.988Z"
    }
   },
   "outputs": [],
   "source": [
    "# 네이버 IT뉴스 게시판에서 근 24시간에 해당하는 페이지 범위 설정\n",
    "pages = page_lists(endpage=20)\n",
    "\n",
    "# get_urls함수에 게시판 링크를 입력해 각 뉴스의 URL 저장\n",
    "prepared_urls = get_urls_naver(pages=pages, hidden_window=True, verbose=False)\n",
    "\n",
    "# 기사를 담을 데이터프레임 생성\n",
    "\n",
    "df_naver = pd.DataFrame({'URL':prepared_urls, '신문사':np.nan, '기자명':np.nan, '제목':np.nan, '본문':np.nan,\n",
    "                   '날짜':np.nan, '연':np.nan, '월':np.nan, '일':np.nan, '요일':np.nan})\n",
    "\n",
    "# 각 네이버 기사에서 필요한 정보 스크래핑하여 데이터프레임에 적재\n",
    "df_naver = news_crawler_naver(df_naver)\n",
    "display(df_naver.head(3))\n",
    "display(df_naver.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74351607",
   "metadata": {},
   "source": [
    "# 네이버 뉴스와 다음 뉴스를 Merge 데이터프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f5b7a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:17.468Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_naver, df_daum], axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f01227",
   "metadata": {},
   "source": [
    "# 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b477852",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:17.649Z"
    }
   },
   "outputs": [],
   "source": [
    "# raw text와 processed text를 비교하기 위해 copy\n",
    "df_preprocess = df.copy()\n",
    "df_preprocess['본문'] = df_preprocess['본문'].str.upper() # 전부 대문자로 변경\n",
    "\n",
    "# twitter 객체에 Noun 단어 adding\n",
    "twitter = Twitter()\n",
    "\n",
    "# 사용자 정의 명사 지정 리스트 받기\n",
    "add_words = get_addwords()\n",
    "# 불용어 리스트 받기\n",
    "stop_words = get_stopwords()\n",
    "\n",
    "for noun in add_words:\n",
    "    twitter.add_dictionary(noun, 'Noun')\n",
    "\n",
    "# re와 ckonlpy로 전처리\n",
    "articles = df_preprocess['본문']\n",
    "\n",
    "# 본문 Seriese객체에서 index 받아오기\n",
    "# 기사의 건수(약 1400건)만큼 iter\n",
    "for idx in tqdm(range(len(articles))): \n",
    "    # re로 기본적인 전처리\n",
    "    text = articles[idx]\n",
    "    to_remove = '[\\n,@\\'()‘“”’%./■△\\\"·]+'\n",
    "    text = re.sub(to_remove, '', text)\n",
    "    \n",
    "    # ckonlpy로 ' '로 구분된 string형태의 corpus 생성\n",
    "    contents =''\n",
    "    for temp_word in twitter.nouns(text):\n",
    "        # 한글자와 불용어 제외\n",
    "        if (len(temp_word) > 1)&(temp_word not in stop_words):\n",
    "            contents = contents + ' ' + temp_word\n",
    "    \n",
    "    # 전처리를 거친 corpus를 df_preprocess의 본문에 저장\n",
    "    df_preprocess.loc[idx, '본문'] = contents.strip()\n",
    "\n",
    "# 중복 제거\n",
    "df_preprocess = df_preprocess.drop_duplicates(subset=['본문'])\n",
    "    \n",
    "######################################## Check result\n",
    "sleep(2)\n",
    "print(\"전처리 전 :\")\n",
    "print(\"*\"*50)\n",
    "display(df.head(3))\n",
    "display(df.tail(3))\n",
    "print('\\n\\n')\n",
    "print(\"전처리 후 :\")\n",
    "print(\"*\"*50)\n",
    "display(df_preprocess.head(3))\n",
    "display(df_preprocess.tail(3))\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af02235",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:17.769Z"
    }
   },
   "outputs": [],
   "source": [
    "articles = df_preprocess['본문'].tolist()\n",
    "articles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734daa5",
   "metadata": {},
   "source": [
    "# 토픽 모델링 및 Topic Num 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498726d2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:17.918Z"
    }
   },
   "outputs": [],
   "source": [
    "# 리스트 내 리스트 형태로 저장\n",
    "preprocessed_articles = [article.split(' ') for article in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f76623",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:17.977Z"
    }
   },
   "outputs": [],
   "source": [
    "# corpora.Dictionary\n",
    "dictionary = corpora.Dictionary(preprocessed_articles)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.6)\n",
    "\n",
    "corpus = [dictionary.doc2bow(article) for article in preprocessed_articles]\n",
    "texts = [preprocessed_articles[idx] for idx in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaec9f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.069Z"
    }
   },
   "outputs": [],
   "source": [
    "PARAM = {\n",
    "    'RANGES':30,\n",
    "    'PASSES':1,\n",
    "    'ITER':100,\n",
    "    'COHERENCE_METRIC':'c_v',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370ea0a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.159Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2부터 20까지의 토픽 수를 비교하며 정합도 점수 기록\n",
    "news_coherence_scores = []\n",
    "\n",
    "for i in tqdm(range(10, PARAM['RANGES']+1), desc=\"Operating All Topic Ranges\"):\n",
    "    model = LdaModel(corpus=corpus, num_topics=i, id2word=dictionary, passes=PARAM['PASSES'],\n",
    "                     iterations=PARAM['ITER'])#, alpha=PARAM['ALPHA'], eta=PARAM['ETA'])\n",
    "    coherence_model = CoherenceModel(model=model, texts=texts, corpus=corpus, dictionary=dictionary, coherence=PARAM['COHERENCE_METRIC'])\n",
    "    coherence_lda = coherence_model.get_coherence()\n",
    "    news_coherence_scores.append(coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a0b55",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.248Z"
    }
   },
   "outputs": [],
   "source": [
    "k = [i for i in range(10, PARAM['RANGES']+1)]\n",
    "x = np.array(k)\n",
    "y = np.array(news_coherence_scores)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Number Of Topic(2-\"+str(PARAM['RANGES'])+\")\")\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf179f",
   "metadata": {},
   "source": [
    "# Topic Num이 최적화된 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36ef09",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.399Z"
    }
   },
   "outputs": [],
   "source": [
    "find_best = np.array([news_coherence_scores])\n",
    "Best_Num_Of_Topic = int(np.where(y==find_best.max())[0][0]+10)\n",
    "print(\"최적의 토픽 수 :\", Best_Num_Of_Topic)\n",
    "print(\"정합도 점수 :\", round(find_best.max(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f63f4b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.489Z"
    }
   },
   "outputs": [],
   "source": [
    "num_topics = Best_Num_Of_Topic\n",
    "lda_model = LdaModel(corpus, num_topics, dictionary, passes=PARAM['PASSES'], iterations=PARAM['ITER'])#, alpha=PARAM['ALPHA'], eta=PARAM['ETA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a7f7d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.548Z"
    }
   },
   "outputs": [],
   "source": [
    "# LDA 시각화\n",
    "pyLDAvis.enable_notebook()\n",
    "p = pyLDAvis.gensim_models.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary)\n",
    "pyLDAvis.display(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a56c08",
   "metadata": {},
   "source": [
    "# 각 토픽에 정합하는 기사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728fee31",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.698Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 각 문서에 대한 주제 분포 가져오기\n",
    "document_topics = [lda_model.get_document_topics(doc) for doc in corpus]\n",
    "# document_topics # 1382개\n",
    "\n",
    "main_topic_list = []\n",
    "\n",
    "for article_idx, article in enumerate(document_topics):\n",
    "    max_score = 1e-8\n",
    "    max_topic_num = -1e-8\n",
    "    \n",
    "    # 한 기사안에서 토픽 : 점수\n",
    "    for topicnum, score in article:\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_topic_num = topicnum\n",
    "    #main_topic_list.append((str(max_topic_num+1)+'번토픽', max_score))\n",
    "    main_topic_list.append((int(max_topic_num)+1, max_score))\n",
    "\n",
    "main_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520e9e4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.757Z"
    }
   },
   "outputs": [],
   "source": [
    "# 토픽과 점수 추가하여 df_merged로 합치기\n",
    "df_score = pd.DataFrame(main_topic_list, columns=['토픽', '점수'])\n",
    "df_merged = pd.concat([df_preprocess, df_score], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46644c33",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:18.848Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 높은 점수 순서대로 정렬한 후, 토픽으로 group을 생성한 후, 상위 5개씩 추출\n",
    "df_merged = df_merged.drop_duplicates(subset=['제목'])\n",
    "df_merged = df_merged.sort_values('점수', ascending=False)\n",
    "df_result = df_merged.groupby('토픽').head(5)\n",
    "df_result = df_result.sort_values('토픽', ignore_index=True)\n",
    "df_result['토픽'] = df_result['토픽'].astype(int)\n",
    "df_result = df_result[['URL', '토픽', '점수', '제목', '본문']]\n",
    "# 최대 행 제한 해제\n",
    "pd.set_option('display.max_rows', None)\n",
    "# 최대 열 제한 해제\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdd1d190",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T02:05:53.404383Z",
     "start_time": "2023-07-04T02:05:53.376290Z"
    }
   },
   "source": [
    "# 토픽 별 결과 확인\n",
    "display(df_result[df_result['토픽']==1])\n",
    "display(df_result[df_result['토픽']==2])\n",
    "display(df_result[df_result['토픽']==3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab399a",
   "metadata": {},
   "source": [
    "# 확인한 결과에서, 메일에 사용할 기사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacef405",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:19.418Z"
    }
   },
   "outputs": [],
   "source": [
    "select_topic = input('사용할 토픽을 입력하세요')\n",
    "select_topic = select_topic.split(' ')\n",
    "\n",
    "cond1 = (df_result['토픽']==int(select_topic[0]))\n",
    "cond2 = (df_result['토픽']==int(select_topic[1]))\n",
    "cond3 = (df_result['토픽']==int(select_topic[2]))\n",
    "\n",
    "df_result = df_result[cond1|cond2|cond3]\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70010639",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:19.597Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_num, topic_keywords = [int(select_topic[0]), int(select_topic[1]), int(select_topic[2])], ['토픽1', '토픽2', '토픽3']\n",
    "df_result.loc[df_result['토픽'].isin(topic_num), '토픽'] = df_result['토픽'].map(dict(zip(topic_num, topic_keywords)))\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd0dd8",
   "metadata": {},
   "source": [
    "# 메일링 형식으로 데이터프레임 가공 (+ 기사요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05ddc6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T03:59:20.948Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inner Join으로 본문 컬럼 다시 가져와 추가\n",
    "df_final = pd.merge(df_result, df[['URL', '본문']], on='URL', how='inner')\n",
    "\n",
    "# 컬럼명 재설정\n",
    "df_final = df_final.rename(columns={'본문_x':'본문', '본문_y':'원본', 'URL':'link', '제목':'title', '토픽':'topic'})\n",
    "df_final = df_final.rename(columns={'본문':'wc'})\n",
    "\n",
    "# 빈 요약 컬럼 추가\n",
    "df_final['desc'] = np.nan\n",
    "\n",
    "# 가독성을 위해 순서 변경\n",
    "df_final = df_final[['topic', 'link', 'wc', 'desc', '원본', 'title']]\n",
    "\n",
    "# 네이버 클로바를 이용한 요약 추가\n",
    "df_final = df_final['원본'].apply(summarize_text)\n",
    "\n",
    "# 본문 요약에 사용한 원본 컬럼 삭제\n",
    "df_final = df_final.drop(columns=['원본'])\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83123e28",
   "metadata": {},
   "source": [
    "# 워드클라우드 생성 및 wordclouds 폴더에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da39325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정\n",
    "width = 580\n",
    "height = 338\n",
    "max_words=30\n",
    "mask = cv2.imread('./image/circle.png')\n",
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac234332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드 하는 for문 짜기\n",
    "\n",
    "# topic = input('토픽을 입력해주세요.')\n",
    "\n",
    "# text = ' '.join(df[df['topic']==topic]['desc'])\n",
    "# wordcloud = WordCloud(font_path='C:/Windows/Fonts/malgun.ttf', width=width, height=height, max_words=max_words,\n",
    "#                       background_color='white', collocations=False, prefer_horizontal=1, mask=mask).generate(text)\n",
    "# plt.figure(figsize=(width/100, height/100))\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "# # save\n",
    "# image = wordcloud.to_image()\n",
    "# image.save(formatted_time+'_'+topic+'.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a489cec",
   "metadata": {},
   "source": [
    "# git push 후, 데이터 프레임에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Documents/DA28_final_PagePalette/news\n",
    "!git add *\n",
    "!git commit -m 'upload wordclouds'\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1414269",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-04T04:02:05.107Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/jinn0135/DA28_final_PagePalette/blob/news/news/wordclouds/     #####.jpg    ?raw=true"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c40026e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-04T02:05:53.931183Z",
     "start_time": "2023-07-04T02:05:53.914855Z"
    }
   },
   "source": [
    "now = datetime.now()\n",
    "formatted_time = now.strftime(\"%Y-%m-%d_%p\")\n",
    "formatted_time = formatted_time.lower()\n",
    "\n",
    "df_final.to_csv(formatted_time + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
