{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8079a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2316e246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>pw</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>large_category</th>\n",
       "      <th>middle_category</th>\n",
       "      <th>selected_book_isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1234</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>소설,소설,시에세이</td>\n",
       "      <td>영미소설,판타지소설,한국시</td>\n",
       "      <td>123456789,234567891,345678912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  email    pw  gender  age large_category middle_category  \\\n",
       "0     0  1234  female   20     소설,소설,시에세이  영미소설,판타지소설,한국시   \n",
       "\n",
       "              selected_book_isbn  \n",
       "0  123456789,234567891,345678912  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>large_category</th>\n",
       "      <th>middle_category</th>\n",
       "      <th>b_rank</th>\n",
       "      <th>rate</th>\n",
       "      <th>count</th>\n",
       "      <th>isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>해리포터</td>\n",
       "      <td>조앤K롤링</td>\n",
       "      <td>소설,소설</td>\n",
       "      <td>영미소설,판타지소설</td>\n",
       "      <td>20</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1324</td>\n",
       "      <td>566465456545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title author large_category middle_category  b_rank  rate  count  \\\n",
       "0  해리포터  조앤K롤링          소설,소설      영미소설,판타지소설      20   9.4   1324   \n",
       "\n",
       "           isbn  \n",
       "0  566465456545  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_info = pd.DataFrame({'email':'0', 'pw':'1234', 'gender':'female', 'age':20,\n",
    "                        'large_category':'소설,소설,시에세이', 'middle_category':'영미소설,판타지소설,한국시',\n",
    "                        'selected_book_isbn':'123456789,234567891,345678912'}, index=[0])\n",
    "book_df = pd.DataFrame({'title':'해리포터', 'author':'조앤K롤링', \n",
    "              'large_category':'소설,소설', 'middle_category':'영미소설,판타지소설', \n",
    "              'b_rank':20, 'rate':9.4, 'count':1324, 'isbn': 566465456545}, index=[0])\n",
    "display(user_info)\n",
    "display(book_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efccd13c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(select_dfs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     81\u001b[0m check \u001b[38;5;241m=\u001b[39m sortBook(user_info)\n\u001b[1;32m---> 82\u001b[0m \u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 74\u001b[0m, in \u001b[0;36msortBook.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g2 \u001b[38;5;129;01min\u001b[39;00m g2s\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m g2\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecomm1_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg2_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenres[g1][g2][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[:g2_c,:]\n\u001b[0;32m     76\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m i\n",
      "Cell \u001b[1;32mIn[29], line 60\u001b[0m, in \u001b[0;36msortBook.recomm1_rank\u001b[1;34m(self, g1, g2, n, check)\u001b[0m\n\u001b[0;32m     57\u001b[0m     idx \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiddle_category\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mg2]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     59\u001b[0m cvect \u001b[38;5;241m=\u001b[39m CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 60\u001b[0m cvect_g2 \u001b[38;5;241m=\u001b[39m \u001b[43mcvect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmiddle_category\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m csim_g2 \u001b[38;5;241m=\u001b[39m cosine_similarity(cvect_g2, cvect_g2)\u001b[38;5;241m.\u001b[39margsort()[:,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     63\u001b[0m sim_idx \u001b[38;5;241m=\u001b[39m csim_g2[idx, :n]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1387\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1380\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1381\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m             )\n\u001b[0;32m   1385\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1390\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1274\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1273\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:106\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:239\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    236\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     )\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "class sortBook():\n",
    "    def __init__(self, user_info):\n",
    "        self.gender = user_info['gender'].values[0]\n",
    "        self.age = user_info['age'].values[0]\n",
    "        g1s = user_info['large_category'].values[0].split(',')\n",
    "        g2s = user_info['middle_category'].values[0].split(',')\n",
    "        self.genres = {g1:{'df':self.call_df(g1),\n",
    "                           g2:{}} for g1,g2 in zip(g1s, g2s)}\n",
    "    \n",
    "    def connect_mysql(self, local=True, connect=True):\n",
    "        if connect:\n",
    "            if local:\n",
    "                host, user, pw = 'localhost', 'root', '1234'\n",
    "            else:\n",
    "                host, user, pw = '192.168.0.176', 'pagepalette', 'pagepalette0528'\n",
    "            self.db = pymysql.connect(host=host, port=3306, user=user, passwd=pw, db='pagepalette', \n",
    "                                      charset='utf8', cursorclass=pymysql.cursors.DictCursor)\n",
    "            self.cursor = self.db.cursor()\n",
    "        else:\n",
    "            self.db.commit()\n",
    "            self.db.close\n",
    "    \n",
    "    def call_df(self, g1):\n",
    "        self.connect_mysql(local=False, connect=True)\n",
    "        sql = 'SELECT * FROM gyobo_{}'.format(g1)\n",
    "        self.cursor.execute(sql)\n",
    "        df = pd.DataFrame(self.cursor.fetchall())\n",
    "        self.connect_mysql(local=False, connect=False)\n",
    "        \n",
    "        df.drop_duplicates(subset=['title','author'], ignore_index=True, inplace=True)\n",
    "        return df.dropna()\n",
    "    \n",
    "    def recomm1_rank(self, g1, g2, n=240, check=True):\n",
    "        df = self.genres[g1]['df'].copy()\n",
    "        \n",
    "        try: idx = df[df['middle_category']==g2].index.values[0]\n",
    "        except:\n",
    "            check = False\n",
    "            df = pd.concat([df, pd.DataFrame({'middle_category':[g2]})], ignore_index=True)\n",
    "            idx = df[df['middle_category']==g2].index.values\n",
    "\n",
    "        cvect = CountVectorizer(ngram_range=(1,3))\n",
    "        cvect_g2 = cvect.fit_transform(df['middle_category'])\n",
    "        csim_g2 = cosine_similarity(cvect_g2, cvect_g2).argsort()[:,::-1]\n",
    "        \n",
    "        sim_idx = csim_g2[idx, :n].reshape(-1)\n",
    "        sim_idx = sim_idx if check else sim_idx[sim_idx != idx]\n",
    "        self.genres[g1][g2]['df'] = df.iloc[sim_idx].sort_values(['b_rank','rate'], ascending=[True, False])\n",
    "    \n",
    "    def __call__(self):\n",
    "        select_dfs, i = [], 1\n",
    "        g1_n, g1_c = 480//len(self.genres.keys()), 12//len(self.genres.keys())\n",
    "        for g1, g2s in self.genres.items():\n",
    "            g2_n, g2_c = g1_n//(len(g2s.keys())-1), g1_c//(len(g2s.keys())-1)\n",
    "            for g2 in g2s.keys():\n",
    "                if g2=='df': continue\n",
    "                self.recomm1_rank(g1, g2, g2_n)\n",
    "                df = self.genres[g1][g2]['df'].iloc[:g2_c,:]\n",
    "                df['order'] = i\n",
    "                i += 1\n",
    "                select_dfs.append(df)\n",
    "        return pd.concat(select_dfs, axis=0)\n",
    "    \n",
    "check = sortBook(user_info)\n",
    "check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0d1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e15bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommBook():\n",
    "    def __init__(self, user_info):\n",
    "        self.gender = user_info['gender'].values[0]\n",
    "        self.age = user_info['age'].values[0]\n",
    "        \n",
    "        sort = sortBook(user_info)\n",
    "        sort_dfs = sort()\n",
    "        g1s = user_info['large_category'].values[0].split(',')\n",
    "        g2s = user_info['middle_category'].values[0].split(',')\n",
    "        self.selected_n = len(g2s)\n",
    "        select_books = user_info['selected_book_isbn'].values[0].split(',')\n",
    "        if self.selected_n==1:\n",
    "            selected_books = [selected_books]\n",
    "        elif self.selected_n==2:\n",
    "            selected_books = [selected_books[:1], selected_books[2:]]\n",
    "        elif self.selected_n==3:\n",
    "            selected_books = [selected_books[:1], selected_books[2], selected_books[3]]\n",
    "        self.genres = {g1:{g2:{'isbn':isbn,\n",
    "                               'df':sort_dfs[g1][g2]['df']}} for g1,g2,isbn in zip(g1s, g2s, select_books)}\n",
    "        self.df_ga = self.make_df_ga()\n",
    "    \n",
    "    def connect_mysql(self, local=True, connect=True):\n",
    "        if connect:\n",
    "            if local:\n",
    "                host, user, pw = 'localhost', 'root', '1234'\n",
    "            else:\n",
    "                host, user, pw = '192.168.0.176', 'pagepalette', 'pagepalette0528'\n",
    "            self.db = pymysql.connect(host=host, port=3306, user=user, passwd=pw, db='pagepalette', \n",
    "                                      charset='utf8', cursorclass=pymysql.cursors.DictCursor)\n",
    "            self.cursor = self.db.cursor()\n",
    "        else:\n",
    "            self.db.commit()\n",
    "            self.db.close\n",
    "    \n",
    "    def make_df_ga(self):\n",
    "        self.connect_mysql(local=False, connect=True)\n",
    "        sql = 'SELECT * FROM {}_{}'.format(self.age, self.gender)\n",
    "        self.cursor.execute(sql)\n",
    "        df = pd.DataFrame(self.cursor.fetchall())\n",
    "        self.connect_mysql(local=False, connect=False)\n",
    "        return df\n",
    "    \n",
    "    def recomm2_rate(self, g1, g2, selected_isbn):\n",
    "        df = self.genres[g1][g2]['df'].copy().reset_index(drop=True)\n",
    "        n = len(df)//2\n",
    "        \n",
    "        cvect = CountVectorizer(ngram_range=(1,3))\n",
    "        cvect_g2 = cvect.fit_transform(df['middle_category'])\n",
    "        csim_g2 = cosine_similarity(cvect_g2, cvect_g2).argsort()[:,::-1]\n",
    "        \n",
    "        idx = df[df['isbn'] == selected_isbn].index.values\n",
    "        sim_idx = csim_g2[idx, :n].reshape(-1)\n",
    "        sim_idx = sim_idx[sim_idx != idx]\n",
    "        return df.iloc[sim_idx].sort_values(['b_rank', 'rate'], ascending=[True, False])\n",
    "    \n",
    "    def recomm2_ga(self, g1, g2, selected_isbn):\n",
    "        df = self.recomm2_rate(g1, g2, selected_isbn)\n",
    "        df_ga = pd.merge(self.genres[g1][g2]['df'], self.df_ga, how='inner', \n",
    "                         left_on='isbn', right_on='agender_isbn')[['agender_rank','agender_isbn']]\n",
    "        \n",
    "        bins, labels = [i for i in range(0,210,10)], [i for i in range(-200, 0, 10)]\n",
    "        df_ga['ga_new_rank'] = pd.cut(df_ga['{}_{}_rank'.format(self.age, self.gender)], bins=bins, labels=labels)\n",
    "        new_df = pd.merge(df, df_ga, how='left', left_on='isbn', right_on='agender_isbn').drop(columns=['agender_isbn'])\n",
    "        new_df['ga_new_rank'] = new_df['ga_new_rank'].astype({'ga_new_rank':float})\n",
    "        new_df['ga_new_rank'] = new_df['ga_new_rank'].fillna(0)\n",
    "        new_df['new_rank'] = new_df['b_rank'] + new_df['ga_new_rank']\n",
    "        return new_df.sort_values(['new_rank','rate'], ascending=[True, False])\n",
    "    \n",
    "    def __call__(self):\n",
    "        result_li = []\n",
    "        for g1, g2s in self.genres.items():\n",
    "            for g2 in g2s.keys():\n",
    "                if g2=='df': continue\n",
    "                for i, selected_isbn in enumerate(self.genres[g1][g2]['isbn']):\n",
    "                    author = self.genres[g1][g2]['df'].loc[self.genres[g1][g2]['df']['isbn']==selected_isbn, 'author']\n",
    "                    author_df = self.genres[g1][g2]['df'][self.genres[g1][g2]['df']['author']=='author']\n",
    "                    df = pd.concat([self.recomm2_ga(g1, g2, selected_isbn).iloc[:50,:], author_df], axis=0)\n",
    "                    df.drop_duplicates(subset=['title','author'], ignore_index=True, inplace=True)\n",
    "\n",
    "                    recomm_n = 2 if self.selected_n<=2 else 1\n",
    "                    if self.selected_n==3 and i==0: recomm_n = 2\n",
    "                    idx = np.random.randint(len(df), size=recomm_n)\n",
    "                    result_li.append(df.loc[idx])\n",
    "        result_df = pd.concat(result_li, axis=0)\n",
    "        \n",
    "        print('추천하는 책입니다.')\n",
    "        display(result_df)\n",
    "        \n",
    "myrecomm = recommBook(user_info)\n",
    "myrecomm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472d6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7e1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b90e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b69e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc823972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user info: male, 20, {'시에세이': ['영미에세이']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>brank</th>\n",
       "      <th>rate</th>\n",
       "      <th>count</th>\n",
       "      <th>isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>915.0</td>\n",
       "      <td>전쟁 같은 맛</td>\n",
       "      <td>그레이스 M. 조</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.791169e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>하늘과 바람과 별과 시</td>\n",
       "      <td>윤동주100년포럼</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>한국시, 현대시,</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.93</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.791158e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>946.0</td>\n",
       "      <td>불안</td>\n",
       "      <td>알랭 드 보통</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.44</td>\n",
       "      <td>343.0</td>\n",
       "      <td>9.788957e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>851.0</td>\n",
       "      <td>위로를 주는 빵집, 오렌지 베이커리</td>\n",
       "      <td>키티 테이트 외</td>\n",
       "      <td>시/에세이, 요리,</td>\n",
       "      <td>나라별 에세이, 영미에세이, 요리에세이,</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.791156e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>862.0</td>\n",
       "      <td>월든(완결판)</td>\n",
       "      <td>헨리 데이빗 소로우</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>336.0</td>\n",
       "      <td>9.788957e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>866.0</td>\n",
       "      <td>삶으로 다시 떠오르기</td>\n",
       "      <td>에크하르트 톨레</td>\n",
       "      <td>시/에세이, 시/에세이,</td>\n",
       "      <td>테마에세이, 명상/치유에세이, 나라별 에세이, 영미에세이,</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9.65</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.791195e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>888.0</td>\n",
       "      <td>소년과 두더지와 여우와 말</td>\n",
       "      <td>찰리 맥커시</td>\n",
       "      <td>시/에세이, 시/에세이,</td>\n",
       "      <td>테마에세이, 그림에세이, 나라별 에세이, 영미에세이,</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.81</td>\n",
       "      <td>146.0</td>\n",
       "      <td>9.788997e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>897.0</td>\n",
       "      <td>H마트에서 울다</td>\n",
       "      <td>미셸 자우너</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>179.0</td>\n",
       "      <td>9.788955e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>801.0</td>\n",
       "      <td>사랑은 찾는 게 아니라 만드는 것이다</td>\n",
       "      <td>정이수</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 한국에세이,</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9.58</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.791193e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>802.0</td>\n",
       "      <td>나의 봄날인 너에게</td>\n",
       "      <td>여수언니(정혜영)</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 한국에세이,</td>\n",
       "      <td>102.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.791131e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>803.0</td>\n",
       "      <td>다음으로 가는 마음</td>\n",
       "      <td>박지완</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 한국에세이,</td>\n",
       "      <td>103.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.791198e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>812.0</td>\n",
       "      <td>곰돌이 푸, 행복한 일은 매일 있어</td>\n",
       "      <td>곰돌이 푸</td>\n",
       "      <td>시/에세이, 시/에세이, 시/에세이,</td>\n",
       "      <td>테마에세이, 캐릭터에세이, 테마에세이, 그림에세이, 나라별 에세이, 영미에세이,</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.24</td>\n",
       "      <td>3724.0</td>\n",
       "      <td>9.788926e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                 title      author                genre_1  \\\n",
       "843       915.0               전쟁 같은 맛   그레이스 M. 조                시/에세이,    \n",
       "2           2.0          하늘과 바람과 별과 시   윤동주100년포럼                시/에세이,    \n",
       "874       946.0                    불안     알랭 드 보통                시/에세이,    \n",
       "781       851.0   위로를 주는 빵집, 오렌지 베이커리    키티 테이트 외            시/에세이, 요리,    \n",
       "792       862.0               월든(완결판)  헨리 데이빗 소로우                시/에세이,    \n",
       "796       866.0           삶으로 다시 떠오르기    에크하르트 톨레         시/에세이, 시/에세이,    \n",
       "817       888.0        소년과 두더지와 여우와 말      찰리 맥커시         시/에세이, 시/에세이,    \n",
       "825       897.0              H마트에서 울다      미셸 자우너                시/에세이,    \n",
       "734       801.0  사랑은 찾는 게 아니라 만드는 것이다         정이수                시/에세이,    \n",
       "735       802.0            나의 봄날인 너에게   여수언니(정혜영)                시/에세이,    \n",
       "736       803.0            다음으로 가는 마음         박지완                시/에세이,    \n",
       "744       812.0   곰돌이 푸, 행복한 일은 매일 있어       곰돌이 푸  시/에세이, 시/에세이, 시/에세이,    \n",
       "\n",
       "                                           genre_2  brank   rate   count  \\\n",
       "843                               나라별 에세이, 영미에세이,    15.0  10.00     1.0   \n",
       "2                                       한국시, 현대시,    28.0   9.93   112.0   \n",
       "874                               나라별 에세이, 영미에세이,    47.0   9.44   343.0   \n",
       "781                        나라별 에세이, 영미에세이, 요리에세이,    51.0  10.00     1.0   \n",
       "792                               나라별 에세이, 영미에세이,    62.0   9.42   336.0   \n",
       "796              테마에세이, 명상/치유에세이, 나라별 에세이, 영미에세이,    66.0   9.65   256.0   \n",
       "817                 테마에세이, 그림에세이, 나라별 에세이, 영미에세이,    88.0   9.81   146.0   \n",
       "825                               나라별 에세이, 영미에세이,    97.0   9.74   179.0   \n",
       "734                               나라별 에세이, 한국에세이,   101.0   9.58    12.0   \n",
       "735                               나라별 에세이, 한국에세이,   102.0   9.87    43.0   \n",
       "736                               나라별 에세이, 한국에세이,   103.0  10.00     4.0   \n",
       "744  테마에세이, 캐릭터에세이, 테마에세이, 그림에세이, 나라별 에세이, 영미에세이,   112.0   9.24  3724.0   \n",
       "\n",
       "             isbn  \n",
       "843  9.791169e+12  \n",
       "2    9.791158e+12  \n",
       "874  9.788957e+12  \n",
       "781  9.791156e+12  \n",
       "792  9.788957e+12  \n",
       "796  9.791195e+12  \n",
       "817  9.788997e+12  \n",
       "825  9.788955e+12  \n",
       "734  9.791193e+12  \n",
       "735  9.791131e+12  \n",
       "736  9.791198e+12  \n",
       "744  9.788926e+12  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시에세이_영미에세이 마음에 드는 책의 idx 두 개 입력:874 781\n",
      "추천하는 책입니다.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>brank</th>\n",
       "      <th>rate</th>\n",
       "      <th>count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>20_male_rank</th>\n",
       "      <th>ga_new_rank</th>\n",
       "      <th>new_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>470.0</td>\n",
       "      <td>태도에 관하여</td>\n",
       "      <td>임경선</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 한국에세이,</td>\n",
       "      <td>518.0</td>\n",
       "      <td>9.47</td>\n",
       "      <td>152.0</td>\n",
       "      <td>9.791160e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>518.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>692.0</td>\n",
       "      <td>얀 마텔 101통의 문학 편지</td>\n",
       "      <td>얀 마텔</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>342.0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.791160e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>411.0</td>\n",
       "      <td>나는 간호사, 사람입니다</td>\n",
       "      <td>김현아</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 한국에세이,</td>\n",
       "      <td>558.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.791198e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897.0</td>\n",
       "      <td>H마트에서 울다</td>\n",
       "      <td>미셸 자우너</td>\n",
       "      <td>시/에세이,</td>\n",
       "      <td>나라별 에세이, 영미에세이,</td>\n",
       "      <td>97.0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>179.0</td>\n",
       "      <td>9.788955e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             title  author  genre_1           genre_2  brank  \\\n",
       "45       470.0           태도에 관하여     임경선  시/에세이,   나라별 에세이, 한국에세이,   518.0   \n",
       "26       692.0  얀 마텔 101통의 문학 편지    얀 마텔  시/에세이,   나라별 에세이, 영미에세이,   342.0   \n",
       "49       411.0     나는 간호사, 사람입니다     김현아  시/에세이,   나라별 에세이, 한국에세이,   558.0   \n",
       "5        897.0          H마트에서 울다  미셸 자우너  시/에세이,   나라별 에세이, 영미에세이,    97.0   \n",
       "\n",
       "     rate  count          isbn  20_male_rank  ga_new_rank  new_rank  \n",
       "45   9.47  152.0  9.791160e+12           NaN          0.0     518.0  \n",
       "26   9.63   24.0  9.791160e+12           NaN          0.0     342.0  \n",
       "49  10.00    1.0  9.791198e+12           NaN          0.0     558.0  \n",
       "5    9.74  179.0  9.788955e+12           NaN          0.0      97.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class recommBook():\n",
    "    def __init__(self, gender, age, genres):\n",
    "        self.gender, self.age = gender, age\n",
    "        self.ga = 2*(age//10)-2 if gender=='female' else 2*(age//10)-1\n",
    "        self.df_ga = self.make_df_ga()\n",
    "        self.genres = {g1:{g2:{} for g2 in g2s} for g1,g2s in genres.items()}\n",
    "        self.selected_n = 0\n",
    "        for g1 in genres.keys():\n",
    "            self.genres[g1]['df'] = self.call_df(g1)\n",
    "            self.selected_n += len(genres[g1])\n",
    "        print('user info: {}, {}, {}'.format(gender, age, genres))\n",
    "        \n",
    "    def call_df(sefl, g1):\n",
    "        df = pd.read_csv('./best_books/gyobo_{}.csv'.format(g1))\n",
    "        df.drop_duplicates(subset=['title','author'], ignore_index=True, inplace=True)\n",
    "        return df.dropna()\n",
    "    \n",
    "    def make_df_ga(self):\n",
    "        df = pd.read_csv('./age_gender_popular_book/{}_{}.csv'.format(self.age, self.gender), \n",
    "                            encoding='cp949', sep='\\t')\n",
    "\n",
    "        df = df.drop(df.iloc[[0, 1, 2]].index.values).reset_index(drop=True)\n",
    "        df = df['제공기관 : 국립중앙도서관'].str.split(''',\"''', expand=True)\n",
    "        df.columns = ['rank', 'title', 'author', 'publisher', 'pub_year','series', 'isbn', 'loan_cnt']\n",
    "        for col in ['title','author','isbn']:\n",
    "            df[col] = df[col].str.replace('\"','')\n",
    "        \n",
    "        df = df.astype({'rank':float,'isbn':float})\n",
    "        df.rename(columns = {'rank':'{}_{}_rank'.format(self.age, self.gender),'isbn':'library_isbn'}, inplace=True)\n",
    "        return df[['{}_{}_rank'.format(self.age, self.gender), 'library_isbn']]\n",
    "    \n",
    "    def recomm1_rank(self, g1, g2, n=240, check=True):\n",
    "        df = self.genres[g1]['df'].copy()\n",
    "        \n",
    "        try: idx = df[df['genre_2']==g2].index.values[0]\n",
    "        except:\n",
    "            check = False\n",
    "            df = pd.concat([df, pd.DataFrame({'genre_2':[g2]})], ignore_index=True)\n",
    "            idx = df[df['genre_2']==g2].index.values\n",
    "\n",
    "        cvect = CountVectorizer(ngram_range=(1,3))\n",
    "        cvect_g2 = cvect.fit_transform(df['genre_2'])\n",
    "        csim_g2 = cosine_similarity(cvect_g2, cvect_g2).argsort()[:,::-1]\n",
    "        \n",
    "        sim_idx = csim_g2[idx, :n].reshape(-1)\n",
    "        sim_idx = sim_idx if check else sim_idx[sim_idx != idx]\n",
    "        self.genres[g1][g2]['df'] = df.iloc[sim_idx].sort_values(['brank','rate'], ascending=[True, False])\n",
    "    \n",
    "    def recomm1(self):\n",
    "#         select_dfs = []\n",
    "        g1_n, g1_c = 480//len(self.genres.keys()), 12//len(self.genres.keys())\n",
    "        for g1, g2s in self.genres.items():\n",
    "            g2_n, g2_c = g1_n//(len(g2s.keys())-1), g1_c//(len(g2s.keys())-1)\n",
    "            for g2 in g2s.keys():\n",
    "                if g2=='df': continue\n",
    "                self.recomm1_rank(g1, g2, g2_n)\n",
    "                df = self.genres[g1][g2]['df'].iloc[:g2_c,:]\n",
    "#                 select_dfs.append(df)\n",
    "                display(df)\n",
    "                if self.selected_n==1:\n",
    "                    idxs = map(int, input('{}_{} 마음에 드는 책의 idx 두 개 입력:'.format(g1,g2)).split())\n",
    "                    self.genres[g1][g2]['isbn'] = [df.loc[idx,'isbn'] for idx in idxs]\n",
    "                else:\n",
    "                    idx = int(input('{}_{} 마음에 드는 책의 idx:'.format(g1, g2)))\n",
    "                    self.genres[g1][g2]['isbn'] = [df.loc[idx,'isbn']]\n",
    "#         pd.concat(select_dfs, axis=0)\n",
    "    \n",
    "    def recomm2_rate(self, g1, g2, selected_isbn):\n",
    "        df = self.genres[g1][g2]['df'].copy().reset_index(drop=True)\n",
    "        n = len(df)//2\n",
    "        \n",
    "        cvect = CountVectorizer(ngram_range=(1,3))\n",
    "        cvect_g2 = cvect.fit_transform(df['genre_2'])\n",
    "        csim_g2 = cosine_similarity(cvect_g2, cvect_g2).argsort()[:,::-1]\n",
    "        \n",
    "        idx = df[df['isbn'] == selected_isbn].index.values\n",
    "        sim_idx = csim_g2[idx, :n].reshape(-1)\n",
    "        sim_idx = sim_idx[sim_idx != idx]\n",
    "        return df.iloc[sim_idx].sort_values(['brank', 'rate'], ascending=[True, False])\n",
    "    \n",
    "    def recomm2_ga(self, g1, g2, selected_isbn):\n",
    "        df = self.recomm2_rate(g1, g2, selected_isbn)\n",
    "        df_ga = pd.merge(self.genres[g1][g2]['df'], self.df_ga, how='inner', \n",
    "                         left_on='isbn', right_on='library_isbn')[['{}_{}_rank'.format(self.age, self.gender),'library_isbn']]\n",
    "        \n",
    "        bins, labels = [i for i in range(0,210,10)], [i for i in range(-200, 0, 10)]\n",
    "        df_ga['ga_new_rank'] = pd.cut(df_ga['{}_{}_rank'.format(self.age, self.gender)], bins=bins, labels=labels)\n",
    "        new_df = pd.merge(df, df_ga, how='left', left_on='isbn', right_on='library_isbn').drop(columns=['library_isbn'])\n",
    "        new_df['ga_new_rank'] = new_df['ga_new_rank'].astype({'ga_new_rank':float})\n",
    "        new_df['ga_new_rank'] = new_df['ga_new_rank'].fillna(0)\n",
    "        new_df['new_rank'] = new_df['brank'] + new_df['ga_new_rank']\n",
    "        return new_df.sort_values(['new_rank','rate'], ascending=[True, False])\n",
    "    \n",
    "    def recomm2(self):\n",
    "        result_li = []\n",
    "        for g1, g2s in self.genres.items():\n",
    "            for g2 in g2s.keys():\n",
    "                if g2=='df': continue\n",
    "                for selected_isbn in self.genres[g1][g2]['isbn']:\n",
    "                    author = self.genres[g1][g2]['df'].loc[self.genres[g1][g2]['df']['isbn']==selected_isbn, 'author']\n",
    "                    author_df = self.genres[g1][g2]['df'][self.genres[g1][g2]['df']['author']=='author']\n",
    "                    df = pd.concat([self.recomm2_ga(g1, g2, selected_isbn).iloc[:50,:], author_df], axis=0)\n",
    "                    df.drop_duplicates(subset=['title','author'], ignore_index=True, inplace=True)\n",
    "\n",
    "                    recomm_n = 2 if self.selected_n<=2 else 1\n",
    "                    idx = np.random.randint(len(df), size=recomm_n)\n",
    "                    result_li.append(df.loc[idx])\n",
    "        result_df = pd.concat(result_li, axis=0)\n",
    "        \n",
    "        print('추천하는 책입니다.')\n",
    "        display(result_df)\n",
    "        \n",
    "gender, age = 'male', 20\n",
    "genres = {\n",
    "#           '소설': ['영미소설','세계문학전집'],\n",
    "          '시에세이': ['영미에세이']\n",
    "#           '인문': ['인문학일반','심리학']\n",
    "         } # g1:[g2_1, g2_2]\n",
    "myrecomm = recommBook(gender, age, genres)\n",
    "# myrecomm.recomm1('소설', '한국소설').iloc[:2,:]\n",
    "myrecomm.recomm1()\n",
    "myrecomm.recomm2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1a5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
